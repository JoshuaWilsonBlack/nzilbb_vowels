% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pca_test.R
\name{pca_test}
\alias{pca_test}
\title{Generate bootstrapped confidence intervals and permutation based null
distribution for PCA analysis.}
\usage{
pca_test(
  pca_data,
  n = 100,
  scale = TRUE,
  variance_confint = 0.95,
  loadings_confint = 0.9
)
}
\arguments{
\item{pca_data}{data fed to the `prcomp` function.}

\item{n}{the number of times to permute and bootstrap that data. **Warning:** high values
will take a long time to compute.}

\item{scale}{whether the PCA variables should be scaled (default = TRUE).}

\item{variance_confint}{size of confidence intervals for variance explained.}

\item{loadings_confint}{size of confidence intervals for index loadings.}
}
\value{
object of class `pca_test`
* `$variance_explained` a tibble
* `$index_loadings` list of length n of significant pairwise
correlations in n permutations of the data (<= 0.05).
}
\description{
Permute and bootstrap data fed to PCA a given number of times. Bootstrapped
data is used to estimate confidence bands for variance explained by each PC
and for each loading. Squared loadings are multiplied by the squared
eigenvalue of the relevant PC. This ranks the loadings of PCs which explain
a lot of variance higher than those from PCs which explain less. This
approach to PCA testing follows Carmago (2022) and Viera (2012). This
approach differs from Carmago's PCAtest package by splitting up the data and
plotting functions and adopting more of the 'tidyverse' dialect.
}
\examples{
\dontrun{pca_test(
    pca_data,
    n = 100,
    scale = TRUE,
    variance_confint = 0.95,
    loadings_confint = 0.9)
}
}
